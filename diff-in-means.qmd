---
title: "Difference in means"
page-layout: custom
format:
  html:
    include-in-header:
      - text: |
          <style>
          #quarto-content {
            padding: 1em 1.5em;
          }
          </style>
---

```{ojs}
//| echo: false

jstat = require("jstat@1.9.6")

clrs = ({
  gold: "#f3d567",
  orange: "#ee9b43",
  coral: "#e74b47",
  crimson: "#b80422",
  navy: "#172767",
  teal: "#19798b"
})

function statLabel(value, textFn, dy, nullValues) {
  const extent = d3.extent([...nullValues, value]);
  const range = extent[1] - extent[0];
  const pos = range === 0 ? 0.5 :
    (value - extent[0]) / range;
  const textAnchor = pos > 0.82 ? "end" :
    pos < 0.18 ? "start" : "middle";
  const dx = textAnchor === "end" ? -10 :
    textAnchor === "start" ? 10 : 0;

  const common = {
    x: d => d, frameAnchor: "top", dy, dx,
    text: textFn,
    fontWeight: "bold", fontSize: 14,
    textAnchor, paintOrder: "stroke"
  };

  return [
    Plot.text([value], {
      ...common,
      stroke: "white", strokeWidth: 4, fill: "black"
    })
  ];
}
```

::::::: {.grid}

::::: {.g-col-12 .g-col-md-4 .sticky}

```{ojs}
//| echo: false

viewof sample_size = Inputs.range([30, 2000], {
  step: 10,
  value: 100,
  label: "Sample size:"
})

viewof effect_size = Inputs.range([-10, 10], {
  step: 1,
  value: 5,
  label: "Difference:"
})

viewof spread = Inputs.range([1, 30], {
  step: 1,
  value: 10,
  label: "Spread (σ):"
})
```

```{ojs}
//| echo: false

sample_data = {
  const data = [];
  for (let i = 0; i < sample_size; i++) {
    const group = Math.random() < 0.5 ? "A" : "B";
    const mean = group === "A" ? 50 : 50 + effect_size;
    data.push({
      group,
      outcome: jstat.normal.sample(mean, spread)
    });
  }
  return data;
}

Plot.plot({
  style: { fontSize: "13px" },
  marginLeft: 50,
  height: 280,
  x: { label: "Outcome" },
  y: { label: null },
  fy: { label: null, domain: ["A", "B"] },
  color: {
    domain: ["A", "B"],
    range: [clrs.navy, clrs.orange]
  },
  marks: [
    Plot.rectY(
      sample_data,
      Plot.binX(
        { y: "count" },
        {
          x: "outcome",
          fill: "group",
          fy: "group",
          thresholds: 20
        }
      )
    ),
    Plot.ruleX(
      [
        { value: group_stats.meanA, group: "A" },
        { value: group_stats.meanB, group: "B" }
      ],
      {
        x: "value",
        fy: "group",
        stroke: "black",
        strokeWidth: 2.5,
        strokeDasharray: "4,3"
      }
    ),
    Plot.text(
      [
        { value: group_stats.meanA, group: "A",
          label: group_stats.meanA.toFixed(1) },
        { value: group_stats.meanB, group: "B",
          label: group_stats.meanB.toFixed(1) }
      ],
      {
        x: "value",
        fy: "group",
        text: "label",
        frameAnchor: "top",
        dy: 12,
        fontSize: 14,
        fontWeight: "bold",
        fill: "black",
        stroke: "white",
        strokeWidth: 4,
        paintOrder: "stroke"
      }
    ),
    Plot.ruleY([0])
  ]
})
```

:::::

::::: {.g-col-12 .g-col-md-8}

:::: {.panel-tabset}

## Step 1: Calculate δ

The sample statistic (δ) is the **difference in means** between the two groups.

```{ojs}
//| echo: false

group_stats = {
  const groups = { A: [], B: [] };
  for (const d of sample_data) {
    groups[d.group].push(d.outcome);
  }

  const meanA = d3.mean(groups.A);
  const meanB = d3.mean(groups.B);
  const nA = groups.A.length;
  const nB = groups.B.length;

  const seA = d3.deviation(groups.A) / Math.sqrt(nA);
  const seB = d3.deviation(groups.B) / Math.sqrt(nB);
  const ciA = [
    meanA - 1.96 * seA,
    meanA + 1.96 * seA
  ];
  const ciB = [
    meanB - 1.96 * seB,
    meanB + 1.96 * seB
  ];

  const diff = meanB - meanA;
  const seDiff = Math.sqrt(
    seA * seA + seB * seB
  );
  const ciDiff = [
    diff - 1.96 * seDiff,
    diff + 1.96 * seDiff
  ];

  return {
    meanA, meanB, nA, nB, diff,
    ciA, ciB, ciDiff
  };
}

obs_stat = group_stats.diff

obs_stat_abs = Math.abs(obs_stat).toFixed(2)
```

The difference in means is **`{ojs} obs_stat.toFixed(2)`**.

```{ojs}
//| echo: false

html`<table class="table table-sm" style="max-width: 500px;">
  <thead>
    <tr>
      <th>Group</th>
      <th>N</th>
      <th>Average</th>
      <th>95% CI</th>
    </tr>
  </thead>
  <tbody>
    <tr style="background-color: ${clrs.navy}11;">
      <td>A</td>
      <td>${group_stats.nA}</td>
      <td>${group_stats.meanA.toFixed(2)}</td>
      <td>[${group_stats.ciA[0].toFixed(2)}, ${group_stats.ciA[1].toFixed(2)}]</td>
    </tr>
    <tr style="background-color: ${clrs.orange}22;">
      <td>B</td>
      <td>${group_stats.nB}</td>
      <td>${group_stats.meanB.toFixed(2)}</td>
      <td>[${group_stats.ciB[0].toFixed(2)}, ${group_stats.ciB[1].toFixed(2)}]</td>
    </tr>
    <tr style="background-color: ${clrs.crimson}; color: white; font-weight: bold;">
      <td>Difference (B − A)</td>
      <td></td>
      <td>${group_stats.diff.toFixed(2)}</td>
      <td>[${group_stats.ciDiff[0].toFixed(2)}, ${group_stats.ciDiff[1].toFixed(2)}]</td>
    </tr>
  </tbody>
</table>`
```

## Step 2: Simulate null world

We create a null distribution by shuffling (or "permuting" to use the official stats term) the group labels. This simulates a world where all the real, measured values are still the same, but where group assignment doesn't matter. **This eliminates all differences between the groups.**

Think of this as being a world where there are no differences between the two groups. Importantly, this *doesn't* mean that the measured difference between the groups is *exactly* 0. There is variation in the data, and that variation is reflected in the null world. What it means is that in the null world, the difference between the two groups is 0 ± some amount.

Here's what one shuffle looks like. Notice that the outcome values stay the same—only the group labels get reassigned:

```{ojs}
//| echo: false

viewof reshuffle = Inputs.button("Reshuffle")
```

```{ojs}
//| echo: false

shuffle_preview = {
  reshuffle;
  const subset = sample_data.slice(0, 8);
  const groups = subset.map(d => d.group);
  const shuffled = groups.slice();
  for (let i = shuffled.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [shuffled[i], shuffled[j]] = [shuffled[j], shuffled[i]];
  }
  return {
    original: subset.map((d, i) => ({
      " ": i + 1,
      Group: d.group,
      Outcome: +d.outcome.toFixed(1)
    })),
    shuffled: subset.map((d, i) => ({
      " ": i + 1,
      Group: shuffled[i],
      Outcome: +d.outcome.toFixed(1)
    }))
  };
}
```

::::: {.grid}

:::: {.g-col-6}

**Original data**

```{ojs}
//| echo: false

Inputs.table(shuffle_preview.original, {
  columns: [" ", "Group", "Outcome"],
  rows: 8,
  sort: false,
  select: false
})
```

::::

:::: {.g-col-6}

**Shuffled data**

```{ojs}
//| echo: false

Inputs.table(shuffle_preview.shuffled, {
  columns: [" ", "Group", "Outcome"],
  rows: 8,
  sort: false,
  select: false
})
```

::::

:::::

When we do this shuffle hundreds of times and compute the difference in means each time, we get a **null distribution**—a picture of what differences look like in a world where groups don't matter.

Here's what this null world looks like:

```{ojs}
//| echo: false

viewof n_reps = Inputs.range([100, 2000], {
  step: 100,
  value: 500,
  label: "Number of simulations:"
})
```

::: {style="width: 75%;"}

```{ojs}
//| echo: false

null_dist = {
  const outcomes = sample_data.map(d => d.outcome);
  const groups = sample_data.map(d => d.group);
  const n = outcomes.length;
  const results = [];

  for (let r = 0; r < n_reps; r++) {
    // Fisher-Yates shuffle of group labels
    const shuffled = groups.slice();
    for (let i = n - 1; i > 0; i--) {
      const j = Math.floor(Math.random() * (i + 1));
      [shuffled[i], shuffled[j]] = [shuffled[j], shuffled[i]];
    }

    let sumA = 0, nA = 0, sumB = 0, nB = 0;
    for (let i = 0; i < n; i++) {
      if (shuffled[i] === "B") {
        sumB += outcomes[i];
        nB++;
      } else {
        sumA += outcomes[i];
        nA++;
      }
    }
    results.push({ stat: sumB / nB - sumA / nA });
  }
  return results;
}

Plot.plot({
  style: { fontSize: "13px" },
  height: 300,
  width: 500,
  x: { label: "Difference (B − A)" },
  y: { label: "Count" },
  marks: [
    Plot.rectY(
      null_dist,
      Plot.binX(
        { y: "count" },
        { x: "stat", fill: clrs.navy, fillOpacity: 0.7 }
      )
    )
  ]
})
```

:::

## Step 3: Put δ in the null world

Next we put δ inside that null world and see how comfortably it fits there.

Is it surprising to see the red line in this null world? Is the line way out to one of the sides, or is it near the middle with the rest of the null world?

::: {style="width: 75%;"}

```{ojs}
//| echo: false

Plot.plot({
  style: { fontSize: "13px" },
  height: 300,
  width: 500,
  x: { label: "Difference (B − A)" },
  y: { label: "Count" },
  marks: [
    Plot.rectY(
      null_dist,
      Plot.binX(
        { y: "count" },
        { x: "stat", fill: clrs.navy, fillOpacity: 0.7 }
      )
    ),
    Plot.ruleX([obs_stat], { stroke: "red", strokeWidth: 3 }),
    ...statLabel(obs_stat, d => `δ = ${d.toFixed(2)}`, 20,
      null_dist.map(d => d.stat))
  ]
})
```

:::

## Step 4: p-value

We can actually quantify the probability of seeing that red line in a null world. This is a **p-value**—the probability of seeing a δ at least that big in a world where there's no difference between the group averages.

::: {style="width: 75%;"}

```{ojs}
//| echo: false

p_value = {
  const abs_obs = Math.abs(obs_stat);
  const extreme = null_dist.filter(
    d => Math.abs(d.stat) >= abs_obs
  ).length;
  return extreme / null_dist.length;
}

p_value_clean = p_value === 0
  ? "< 0.001"
  : p_value.toFixed(3)

p_percent = p_value === 0
  ? "< 0.1%"
  : (p_value * 100).toFixed(1) + "%"

// Pre-bin the null distribution so entire bins get colored
null_bins = {
  const values = null_dist.map(d => d.stat);
  const bin = d3.bin().thresholds(30);
  const bins = bin(values);
  const abs_obs = Math.abs(obs_stat);
  return bins.map(b => ({
    x0: b.x0,
    x1: b.x1,
    count: b.length,
    midpoint: (b.x0 + b.x1) / 2,
    extreme: Math.abs((b.x0 + b.x1) / 2) >= abs_obs
  }));
}

Plot.plot({
  style: { fontSize: "13px" },
  height: 300,
  width: 500,
  x: { label: "Difference (B − A)" },
  y: { label: "Count" },
  marks: [
    Plot.rectY(null_bins, {
      x1: "x0",
      x2: "x1",
      y: "count",
      fill: d => d.extreme ? clrs.coral + "aa" : clrs.navy + "b3",
      stroke: "white",
      strokeWidth: 0.5
    }),
    Plot.ruleX([obs_stat], { stroke: "red", strokeWidth: 3 }),
    ...statLabel(obs_stat, d => `δ = ${d.toFixed(2)}`, 20,
      null_dist.map(d => d.stat)),
    ...statLabel(obs_stat, () => `p = ${p_value_clean}`, 45,
      null_dist.map(d => d.stat))
  ]
})
```

The p-value is **`{ojs} p_value_clean`**

```{ojs}
//| echo: false

html`<p>This means that in a world where there is no difference between the groups, there is a <strong>${p_percent}</strong> chance of seeing a difference of at least <strong>${obs_stat_abs}</strong></p>`
```

:::

## Step 5: Decision

Finally, we have to decide if the p-value meets an evidentiary standard or threshold that would provide us with enough evidence that we *aren't* in the null world (or, in more statsy terms, enough evidence to reject the null hypothesis).

There are lots of possible thresholds. By convention, most people use a threshold (often shortened to α) of 0.05, or 5%. But that's not required! You could have a lower standard with an α of 0.1 (10%), or a higher standard with an α of 0.01 (1%).

```{ojs}
//| echo: false

viewof alpha = Inputs.select([0.10, 0.05, 0.01], {
  label: "Significance threshold (α):",
  value: 0.05
})
```

:::: {.grid}

::: {.g-col-12 .g-col-md-6}

```{ojs}
//| echo: false

{
  if (p_value < alpha) {
    return html`<div class="alert alert-success" role="alert">
      <h5 class="alert-heading">Statistically significant</h5>
      <p>The p-value is <strong>${p_value_clean}</strong> and our threshold for α is <strong>${alpha}</strong></p>
      <p>In a world where there is no difference between the groups, the probability of seeing a difference of at least <strong>${obs_stat_abs}</strong> is <strong>${p_percent}</strong></p>
      <p>Since ${p_value_clean} is less than ${alpha}, we have enough evidence to say that the difference is <strong>statistically significant.</strong></p>
    </div>`;
  } else {
    return html`<div class="alert alert-warning" role="alert">
      <h5 class="alert-heading">Not statistically significant</h5>
      <p>The p-value is <strong>${p_value_clean}</strong> and our threshold for α is <strong>${alpha}</strong></p>
      <p>In a world where there is no difference between the groups, the probability of seeing a difference of at least <strong>${obs_stat_abs}</strong> is <strong>${p_percent}</strong></p>
      <p>Since ${p_value_clean} is greater than ${alpha}, we don't have enough evidence to say that the difference doesn't come from the null world. The difference is thus <strong>not statistically significant.</strong></p>
      <hr>
      <p style="font-size: 0.9em;">This does <strong>not</strong> mean that there is no difference between the groups! We just don't have enough evidence to judge if there's a difference.</p>
    </div>`;
  }
}
```

:::

::: {.g-col-12 .g-col-md-6}

```{ojs}
//| echo: false

Plot.plot({
  style: { fontSize: "13px" },
  height: 300,
  x: { label: "Difference (B − A)" },
  y: { label: "Count" },
  marks: [
    Plot.rectY(null_bins, {
      x1: "x0",
      x2: "x1",
      y: "count",
      fill: d => d.extreme ? clrs.coral + "aa" : clrs.navy + "b3",
      stroke: "white",
      strokeWidth: 0.5
    }),
    Plot.ruleX([obs_stat], { stroke: "red", strokeWidth: 3 }),
    ...statLabel(obs_stat, d => `δ = ${d.toFixed(2)}`, 20,
      null_dist.map(d => d.stat)),
    ...statLabel(obs_stat, () => `p = ${p_value_clean}`, 45,
      null_dist.map(d => d.stat))
  ]
})
```

:::

::::

{{< include _evidentiary-standards.qmd >}}

::::

:::::

:::::::
