[
  {
    "objectID": "regular-p-values.html",
    "href": "regular-p-values.html",
    "title": "Regular p-values",
    "section": "",
    "text": "So far all the examples on this site calculated p-values through simulation—shuffling and resampling to build null worlds.\nIn real life, you won’t actually do this!\nRegular statistical tests like R’s t.test(), prop.test(), and lm() skip the simulation and instead use known theoretical distributions (like the t, F, and \\(\\chi^2\\) distributions) to approximate null worlds and calculate p-values. This theoretical, mathematical p-value is what you see in regular statistical output.\nEven though they’re not based on simulations, the intuition is the same: a p-value is still the probability of seeing a \\(\\delta\\) at least that large in a world where there is no difference.\nCode\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(ggdist)\nlibrary(ggbeeswarm)\nlibrary(parameters)\nlibrary(tinytable)\n\npenguins &lt;- penguins |&gt; drop_na(sex)\n\ntheme_set(theme_minimal(base_size = 14))\n\n# From MoMAColors::moma.colors(\"OKeeffe\")\nclrs &lt;- c(\n  \"#f3d567\",\n  \"#ee9b43\",\n  \"#e74b47\",\n  \"#b80422\",\n  \"#172767\",\n  \"#19798b\"\n)"
  },
  {
    "objectID": "regular-p-values.html#difference-in-means",
    "href": "regular-p-values.html#difference-in-means",
    "title": "Regular p-values",
    "section": "Difference in means",
    "text": "Difference in means\nThis is the same thing the difference in means example calculates through simulation—just computed with a formula instead.\nHere’s the average body mass across species:\n\n\n\n\nCode\navg_weight |&gt; \n  tt()\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                species\n                avg_weight\n              \n        \n        \n        \n                \n                  Adelie\n                  3706.164\n                \n                \n                  Chinstrap\n                  3733.088\n                \n                \n                  Gentoo\n                  5092.437\n                \n        \n      \n    \n\n\n\n\n\n\n\nCode\nggplot(penguins, aes(x = species, y = body_mass, color = species)) +\n  geom_beeswarm(side = -1, size = 1, cex = 1.5) +\n  stat_pointinterval(.width = 0.95, position = position_nudge(x = 0.2)) +\n  scale_y_continuous(labels = label_number(scale_cut = cut_si(\"g\"))) +\n  scale_color_manual(values = c(clrs[2], clrs[4], clrs[5]), guide = \"none\") +\n  labs(x = \"Species\", y = \"Body mass\")\n\n\n\n\n\n\n\n\n\n\n\nWe can ask a couple questions here about the differences in means.\n\nIs there a difference in body mass between Chinstrap and Gentoo penguins?\nWe’re looking at the difference between these two values:\n\n\n\n\nCode\navg_weight |&gt; \n  tt() |&gt; \n  style_tt(i = 2:3, background = clrs[1])\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                species\n                avg_weight\n              \n        \n        \n        \n                \n                  Adelie\n                  3706.164\n                \n                \n                  Chinstrap\n                  3733.088\n                \n                \n                  Gentoo\n                  5092.437\n                \n        \n      \n    \n\n\n\n\n\n\n\nCode\navg_weight |&gt; \n  mutate(highlight = species %in% c(\"Chinstrap\", \"Gentoo\")) |&gt; \n  ggplot(aes(x = species, y = avg_weight, fill = species)) +\n  geom_col(aes(color = highlight), linewidth = 2) +\n  scale_y_continuous(labels = label_number(scale_cut = cut_si(\"g\"))) +\n  scale_color_manual(values = c(NA, clrs[1]), guide = \"none\") +\n  scale_fill_manual(values = c(clrs[2], clrs[4], clrs[5]), guide = \"none\") +\n  labs(x = \"Species\", y = \"Average weight\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nt.test(\n  body_mass ~ species,\n  data = filter(penguins, species %in% c(\"Chinstrap\", \"Gentoo\"))\n)\n\n\n\n    Welch Two Sample t-test\n\ndata:  body_mass by species\nt = -20.765, df = 169.62, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group Chinstrap and group Gentoo is not equal to 0\n95 percent confidence interval:\n -1488.578 -1230.120\nsample estimates:\nmean in group Chinstrap    mean in group Gentoo \n               3733.088                5092.437 \n\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Parameter\n                Difference (SE)\n                p\n                Group\n                species = Chinstrap\n                species = Gentoo\n              \n        \n        \nAlternative hypothesis: true difference in means between group Chinstrap and group Gentoo is not equal to 0\n\n        \n                \n                  body_mass\n                  -1359.35\n                  &lt;0.001\n                  species\n                  3733.09\n                  5092.44\n                \n        \n      \n    \n\n\n\nThe p-value here is essentially zero (p &lt; 2.2 × 10−16). In a world where Chinstrap and Gentoo penguins had the same average body mass, it would be virtually impossible to see a difference this large.\n\n\nIs there a difference in body mass between Adelie and Chinstrap penguins?\nWe’re looking at the difference between these two values:\n\n\n\n\nCode\navg_weight |&gt; \n  tt() |&gt; \n  style_tt(i = 1:2, background = clrs[1])\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                species\n                avg_weight\n              \n        \n        \n        \n                \n                  Adelie\n                  3706.164\n                \n                \n                  Chinstrap\n                  3733.088\n                \n                \n                  Gentoo\n                  5092.437\n                \n        \n      \n    \n\n\n\n\n\n\n\nCode\navg_weight |&gt; \n  mutate(highlight = species %in% c(\"Chinstrap\", \"Adelie\")) |&gt; \n  ggplot(aes(x = species, y = avg_weight, fill = species)) +\n  geom_col(aes(color = highlight), linewidth = 2) +\n  scale_y_continuous(labels = label_number(scale_cut = cut_si(\"g\"))) +\n  scale_color_manual(values = c(NA, clrs[1]), guide = \"none\") +\n  scale_fill_manual(values = c(clrs[2], clrs[4], clrs[5]), guide = \"none\") +\n  labs(x = \"Species\", y = \"Average weight\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nt.test(\n  body_mass ~ species,\n  data = filter(penguins, species %in% c(\"Adelie\", \"Chinstrap\"))\n)\n\n\n\n    Welch Two Sample t-test\n\ndata:  body_mass by species\nt = -0.44793, df = 154.03, p-value = 0.6548\nalternative hypothesis: true difference in means between group Adelie and group Chinstrap is not equal to 0\n95 percent confidence interval:\n -145.66494   91.81724\nsample estimates:\n   mean in group Adelie mean in group Chinstrap \n               3706.164                3733.088 \n\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Parameter\n                Difference (SE)\n                p\n                Group\n                species = Adelie\n                species = Chinstrap\n              \n        \n        \nAlternative hypothesis: true difference in means between group Adelie and group Chinstrap is not equal to 0\n\n        \n                \n                  body_mass\n                  -26.92\n                  0.655\n                  species\n                  3706.16\n                  3733.09"
  },
  {
    "objectID": "regular-p-values.html#one-sample-mean",
    "href": "regular-p-values.html#one-sample-mean",
    "title": "Regular p-values",
    "section": "One-sample mean",
    "text": "One-sample mean\nThis is the theoretical version of the one-sample mean simulation, where we bootstrap a null world centered at a hypothesized value.\n\nIs the average body mass of all penguins in the dataset different from 4000 g?\n\n\n\n\nCode\nmass_summary |&gt; tt()\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                n\n                Sample mean\n                μ₀\n              \n        \n        \n        \n                \n                  333\n                  4207.057\n                  4000\n                \n        \n      \n    \n\n\n\n\n\n\n\nCode\nggplot(penguins, aes(x = body_mass)) +\n  geom_histogram(\n    binwidth = 200,\n    fill = clrs[5], color = \"white\"\n  ) +\n  geom_vline(\n    xintercept = 4000,\n    color = clrs[3], linewidth = 1.5\n  ) +\n  annotate(\n    \"label\",\n    x = 4000, y = Inf, vjust = 1.5,\n    label = \"μ₀ = 4000 g\", size = 4\n  ) +\n  labs(x = \"Body mass (g)\", y = \"Count\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nt.test(penguins$body_mass, mu = 4000)\n\n\n\n    One Sample t-test\n\ndata:  penguins$body_mass\nt = 4.6925, df = 332, p-value = 3.952e-06\nalternative hypothesis: true mean is not equal to 4000\n95 percent confidence interval:\n 4120.256 4293.858\nsample estimates:\nmean of x \n 4207.057 \n\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Parameter\n                Mean (SE)\n                p\n                mu\n              \n        \n        \nAlternative hypothesis: true mean is not equal to 4000\n\n        \n                \n                  body_mass\n                  4207.06\n                  &lt;0.001\n                  4000\n                \n        \n      \n    \n\n\n\nThe p-value tells us the probability of seeing a sample mean this far from 4000 g in a world where the true average really is 4000 g. The small p-value gives us evidence that the true mean is not 4000 g."
  },
  {
    "objectID": "regular-p-values.html#difference-in-proportions",
    "href": "regular-p-values.html#difference-in-proportions",
    "title": "Regular p-values",
    "section": "Difference in proportions",
    "text": "Difference in proportions\nThis is the theoretical version of the difference in proportions simulation.\nIs the proportion of female penguins the same in Adelie and Gentoo species?\n\n\n\n\nCode\npenguins_prop |&gt; tt()\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                species\n                n_female\n                n\n                prop_female\n              \n        \n        \n        \n                \n                  Adelie\n                  73\n                  146\n                  0.500000\n                \n                \n                  Gentoo\n                  58\n                  119\n                  0.487395\n                \n        \n      \n    \n\n\n\n\n\n\n\nCode\nggplot(\n  penguins_prop,\n  aes(x = species, y = prop_female, fill = species)\n) +\n  geom_col() +\n  scale_y_continuous(labels = label_percent()) +\n  scale_fill_manual(\n    values = c(clrs[2], clrs[5]),\n    guide = \"none\"\n  ) +\n  labs(x = \"Species\", y = \"Proportion female\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nprop.test(\n  x = penguins_prop$n_female,\n  n = penguins_prop$n\n)\n\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  penguins_prop$n_female out of penguins_prop$n\nX-squared = 0.0065013, df = 1, p-value = 0.9357\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.1160296  0.1412397\nsample estimates:\n  prop 1   prop 2 \n0.500000 0.487395 \n\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Difference (SE)\n                p\n                Proportion\n              \n        \n        \nAlternative hypothesis: two.sided\n\n        \n                \n                  1.26%\n                  0.936\n                  50.00% / 48.74%\n                \n        \n      \n    \n\n\n\nThis time the p-value is large—both species have roughly the same proportion of females. In a world where the two species truly had the same proportion of females, it would be completely unsurprising to see a difference this small. There is not enough evidence to say the proportions are different; the result is not statistically significant.\nNot every test produces a tiny p-value! A large p-value doesn’t mean there’s no difference—just that the data don’t provide enough evidence to distinguish a real difference from random variation."
  },
  {
    "objectID": "regular-p-values.html#regression",
    "href": "regular-p-values.html#regression",
    "title": "Regular p-values",
    "section": "Regression",
    "text": "Regression\nThis is the theoretical version of the regression slope simulation, where we shuffle the outcome to build a null world where the slope is zero.\nDoes flipper length predict body mass?\n\n\n\n\nCode\nreg_summary |&gt; tt()\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                n\n                Cor(x, y)\n              \n        \n        \n        \n                \n                  333\n                  0.8729789\n                \n        \n      \n    \n\n\n\n\n\n\n\nCode\nggplot(\n  penguins,\n  aes(x = flipper_len, y = body_mass)\n) +\n  geom_point(color = clrs[5], alpha = 0.5) +\n  geom_smooth(\n    method = \"lm\",\n    color = clrs[3], se = FALSE\n  ) +\n  labs(\n    x = \"Flipper length (mm)\",\n    y = \"Body mass (g)\"\n  )\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npenguin_model &lt;- lm(\n  body_mass ~ flipper_len,\n  data = penguins\n)\n\nsummary(penguin_model)\n\n\n\nCall:\nlm(formula = body_mass ~ flipper_len, data = penguins)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1057.33  -259.79   -12.24   242.97  1293.89 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -5872.09     310.29  -18.93   &lt;2e-16 ***\nflipper_len    50.15       1.54   32.56   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 393.3 on 331 degrees of freedom\nMultiple R-squared:  0.7621,    Adjusted R-squared:  0.7614 \nF-statistic:  1060 on 1 and 331 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                Parameter\n                Coefficient (SE)\n                p\n              \n        \n        \n        \n                \n                  (Intercept)\n                  -5872.09 (310.29)\n                  &lt;0.001\n                \n                \n                  flipper len\n                  50.15 (  1.54)\n                  &lt;0.001\n                \n        \n      \n    \n\n\n\nIn regression output, each coefficient has its own p-value. The p-value for flipper_len tests whether the slope is different from zero—in a world where flipper length had no relationship with body mass (a slope of zero), it would be essentially impossible to see a slope this steep (p &lt; 2.2 × 10−16)."
  },
  {
    "objectID": "index.html#there-is-only-one-test",
    "href": "index.html#there-is-only-one-test",
    "title": "Null worlds",
    "section": "There is only one test",
    "text": "There is only one test\nAt their core, all statistical tests† can be conducted by following a universal pattern:\n\nStep 1: Calculate a sample statistic, or \\(\\delta\\) (“delta”). This is the main measure you care about: the difference in means, the average, the median, the proportion, the difference in proportions, the chi-squared value, the slope in a regression model, etc.\nStep 2: Use simulation to invent a world where \\(\\delta\\) is null. Simulate what the world would look like if there was no difference or relationship between two groups, or if there was no difference in proportions, or where the average value is a specific number.\nStep 3: Look at \\(\\delta\\) in the null world. Put the sample statistic in the null world and see if it fits well.\nStep 4: Calculate the probability that \\(\\delta\\) could exist in null world. This is the p-value, or the probability that you’d see a \\(\\delta\\) at least as extreme in a world where there’s no difference.\nStep 5: Decide if \\(\\delta\\) is statistically significant. Choose some evidentiary standard or threshold for deciding if there’s sufficient proof for rejecting the null world. Standard thresholds (from least to most rigorous) are 0.1, 0.05, and 0.01.\n\nThat’s all. Five steps. No need to follow complicated flowcharts to select the best and most appropriate statistical test. No need to decide which pretests you need to run to choose the right flavor of t-test. No need to think about whether you should use a t- or a z- distribution for your test statistic. Simulate instead.\n\n\n\n\n\n\nTiptl;dr\n\n\n\nCalculate a number, simulate a null world, calculate the probability of seeing your number in that null world, and decide if that number is significantly different from what is typically seen in the null world."
  },
  {
    "objectID": "index.html#example-simulations",
    "href": "index.html#example-simulations",
    "title": "Null worlds",
    "section": "Example simulations",
    "text": "Example simulations\nThis site contains a few different illustrations of common statistical tests:\n\nDifference in means\nDifference in proportions\nOne-sample mean\nRegression slope"
  },
  {
    "objectID": "index.html#do-i-have-to-simulate-everything",
    "href": "index.html#do-i-have-to-simulate-everything",
    "title": "Null worlds",
    "section": "Do I have to simulate everything?",
    "text": "Do I have to simulate everything?\nNo!\nYou can use the {infer} package in R to conduct simulation-based hypothesis tests yourself with your own data.\nBut—most likely—you’ll never actually do your own simulation-based testing (which is fine!). Thinking about null worlds is still extremely valuable for understanding the intuition behind hypothesis testing and p-values. This page shows the same tests using regular statistical functions, but interprets the p-values using the same null world logic:\n\nRegular P-values"
  },
  {
    "objectID": "index.html#why-does-this-work",
    "href": "index.html#why-does-this-work",
    "title": "Null worlds",
    "section": "Why does this work?",
    "text": "Why does this work?\nTODO\nAllen Downey\nRichard McElreath\n{infer}\nModernDive - https://moderndive.com/v2/hypothesis-testing.html#ht-case-study"
  },
  {
    "objectID": "index.html#this-all-feels-vaguely-bayesian",
    "href": "index.html#this-all-feels-vaguely-bayesian",
    "title": "Null worlds",
    "section": "This all feels vaguely Bayesian?",
    "text": "This all feels vaguely Bayesian?\nYep. All this simulation thinking is actually part of my clandestine plot to get more people curious about Bayesian statistics. This way of thinking prepares you for Bayesian inference, without actually being Bayesian.\nThis simulation-based approach mirrors a lot of the computational thinking behind Bayesian statistics. In both approaches, we (1) start with an explicit data-generating process and (2) think about uncertainty with simulation instead of formulas.\nBut there’s an important difference in what we’re simulating!\nWith traditional null hypothesis testing, we simulate a null world and ask:\n\nIf this were the world we lived in, how surprising would our observed \\(\\delta\\) be?\n\nBayesian statistics flips this. Instead of asking how extreme our data (or \\(\\delta\\)) is in a single null world, we model uncertainty about the parameter \\(\\delta\\) itself. After combining prior beliefs with observed data, we get a posterior distribution that we can simulate from to ask:\n\nWhat range of values of \\(\\delta\\) are most plausible, given the data we’ve observed?\n\nIf that sounds fun—and if you’d rather say things like “there’s an X% probability that \\(\\delta\\) is positive” or “\\(\\delta\\) is most likely between X and Y” instead of the convoluted “in a world where \\(\\delta\\) is 0ish, there’s an X% probability of seeing a \\(\\delta\\) at least as extreme as what we observed”—check out Bayes Rules! for the best introduction I’ve found to Bayesian modeling.\n\nPhoto by BoliviaInteligente on Unsplash"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Null worlds",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAt least for null hypothesis significance testing (NHST). Bayesian\ninference is different (see more about that below!). ↩︎"
  }
]